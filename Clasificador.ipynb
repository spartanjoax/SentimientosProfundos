{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificador basado en CNN\n",
    "Basado en https://github.com/satojkovic/cnn-text-classification-tf/tree/use_fasttext y https://github.com/jiegzhan/multi-class-text-classification-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joax\\Anaconda2\\envs\\py36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#Hacer imports y cargar stopwords y vectores entrenados\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd  \n",
    "from text_cnn import TextCNN\n",
    "from tensorflow.contrib import learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "archivoTweets = 'tweets_limpios.csv'\n",
    "\n",
    "params = {\n",
    "            \"num_epochs\": 100,\n",
    "            \"batch_size\": 32,\n",
    "            \"filter_sizes\": \"3,4,5,6\",\n",
    "            \"embedding_dim\": 128,\n",
    "            \"num_filters\": 128,\n",
    "            \"l2_reg_lambda\": 0.1,\n",
    "            \"evaluate_every\": 100,\n",
    "            \"dropout_keep_prob\": 0.5\n",
    "        }\n",
    "\n",
    "#Cargar stopwords\n",
    "#df = pd.read_csv(\"Stopwords.txt\",header=None)\n",
    "#spanish_stopwords = df[0].values.tolist()\n",
    "#print(\"Stopwords cargados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se definen métodos de carga y generación de lotes\n",
    "El método de carga de datos obtiene los tweets del CSV pre-procesado. Convierte las polaridades en un array one-hot ya que las CNNs hacen las predicciones en este formato.\n",
    "\n",
    "La generación de lotes toma el conjunto de tweets a entrenar, y lo divide en pequeños grupos para hacer la evaluación menos intensiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Método que carga los textos pre-procesados con sus polaridades y los prepara para el entrenamiento\n",
    "def cargar_datos_etiquetas(filename):\n",
    "    \"\"\"Carga texto y polaridad\"\"\"\n",
    "    df = pd.read_csv(filename)\n",
    "    selected = ['Texto', 'Polaridad']\n",
    "    non_selected = list(set(df.columns) - set(selected))\n",
    "\n",
    "    df = df.drop(non_selected, axis=1) # Elimina las columnas innecesarias\n",
    "    df = df.dropna(axis=0, how='any', subset=selected) # Elimina filas con valores null\n",
    "    df = df.reindex(np.random.permutation(df.index)) # Revuelve el conjunto de datos\n",
    "\n",
    "    # Convierte las polaridades en etiquetas One-hot\n",
    "    labels = sorted(list(set(df[selected[1]].tolist())))\n",
    "    one_hot = np.zeros((len(labels), len(labels)), int)\n",
    "    np.fill_diagonal(one_hot, 1)\n",
    "    label_dict = dict(zip(labels, one_hot))\n",
    "\n",
    "    #Crea listas con los textos y las etiquetas en formato one-hot\n",
    "    x_raw = df[selected[0]].tolist()\n",
    "    y_raw = df[selected[1]].apply(lambda y: label_dict[y]).tolist()\n",
    "    return x_raw, y_raw, df, labels\n",
    "\n",
    "def batch_iter(data, batch_size, num_epochs, shuffle=True):\n",
    "    \"\"\"\n",
    "    Generates a batch iterator for a dataset.\n",
    "    \"\"\"\n",
    "    data = np.array(data)\n",
    "    data_size = len(data)\n",
    "    num_batches_per_epoch = int((len(data)-1)/batch_size) + 1\n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle the data at each epoch\n",
    "        if shuffle:\n",
    "            shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "            shuffled_data = data[shuffle_indices]\n",
    "        else:\n",
    "            shuffled_data = data\n",
    "        for batch_num in range(num_batches_per_epoch):\n",
    "            start_index = batch_num * batch_size\n",
    "            end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "            yield shuffled_data[start_index:end_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método para entrenar la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn():\n",
    "    #Paso 1: Cargar oraciones, etiquetas y parámetros\n",
    "    x_raw, y_raw, df, labels = cargar_datos_etiquetas(archivoTweets)\n",
    "\n",
    "    #Paso 2: Obtiene vectores de las palabras y rellena los textos para tener la misma longitud\n",
    "    max_document_length = max([len(x.split(' ')) for x in x_raw])\n",
    "    logging.info(\" Oración más larga tiene {} palabras. Se agregan 5 para tener espacio de manipulación para nuevas oraciones\".format(max_document_length))\n",
    "    max_document_length += 5\n",
    "    \n",
    "    vocab_processor = learn.preprocessing.VocabularyProcessor(max_document_length)    \n",
    "    my_file = Path(\"fasttext_vocabulario.dat\")\n",
    "    preentrenado = my_file.is_file()\n",
    "    if preentrenado:\n",
    "        logging.info(\" Cargando vectores generados previamente\")\n",
    "        with open('fasttext_vocabulario.dat', 'rb') as fr:\n",
    "            vocab = pickle.load(fr)\n",
    "        embedding = np.load('fasttext_embeddings.npy')\n",
    "\n",
    "        pretrain = vocab_processor.fit(vocab.keys())\n",
    "        x = np.array(list(vocab_processor.transform(x_raw)))\n",
    "        vocab_size = len(vocab)\n",
    "    else:\n",
    "        logging.info(\" Generando vectores\")\n",
    "        x = np.array(list(vocab_processor.fit_transform(x_raw)))\n",
    "        vocab_size = len(vocab_processor.vocabulary_)\n",
    "        \n",
    "    embedding_size = params['embedding_dim']\n",
    "        \n",
    "    y = np.array(y_raw)\n",
    "\n",
    "    #Paso 3: Divide el dataset original en entrenamiento y prueba\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n",
    "\n",
    "    #Paso 4: revuelve el dataset de entrenamiento y divide el de entrenamiento en entrenamiento y validación\n",
    "    shuffle_indices = np.random.permutation(np.arange(len(y_train)))\n",
    "    x_shuffled = x_train[shuffle_indices]\n",
    "    y_shuffled = y_train[shuffle_indices]\n",
    "    x_train, x_dev, y_train, y_dev = train_test_split(x_shuffled, y_shuffled, test_size=0.1)\n",
    "\n",
    "    logging.info(' x_train: {}, x_dev: {}, x_test: {}'.format(len(x_train), len(x_dev), len(x_test)))\n",
    "    logging.info(' y_train: {}, y_dev: {}, y_test: {}'.format(len(y_train), len(y_dev), len(y_test)))\n",
    "\n",
    "    #Paso 5: Construir el grafo y el objeto CNN\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        session_conf = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)\n",
    "        sess = tf.Session(config=session_conf)\n",
    "        with sess.as_default():\n",
    "            #Paso 5.1: Inicializa el clasificador\n",
    "            cnn = TextCNN(\n",
    "                sequence_length=x_train.shape[1],\n",
    "                num_classes=y_train.shape[1],\n",
    "                vocab_size=vocab_size,\n",
    "                embedding_size=params['embedding_dim'],\n",
    "                filter_sizes=list(map(int, params['filter_sizes'].split(\",\"))),\n",
    "                num_filters=params['num_filters'],\n",
    "                l2_reg_lambda=params['l2_reg_lambda'],\n",
    "                pre_trained=preentrenado)\n",
    "\n",
    "            global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "            optimizer = tf.train.AdamOptimizer(1e-3)\n",
    "            grads_and_vars = optimizer.compute_gradients(cnn.loss)\n",
    "            train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step)\n",
    "\n",
    "            timestamp = str(int(time.time()))\n",
    "            out_dir = os.path.abspath(os.path.join(os.path.curdir, \"trained_model_\" + timestamp))\n",
    "\n",
    "            #Direccion para guardar checkpoints\n",
    "            checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
    "            checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")\n",
    "            if not os.path.exists(checkpoint_dir):\n",
    "                os.makedirs(checkpoint_dir)\n",
    "                \n",
    "            #Direccion para guardar modelo final\n",
    "            final_dir = os.path.abspath(os.path.join(out_dir, \"final\"))\n",
    "            final_prefix = os.path.join(checkpoint_dir, \"model\")\n",
    "            if not os.path.exists(final_dir):\n",
    "                os.makedirs(final_dir)\n",
    "                \n",
    "            saver = tf.train.Saver(tf.global_variables())\n",
    "            \n",
    "            #Guarda las etiquetas en un archivo JSON: labels.json para hacer predicciones luego\n",
    "            with open(os.path.join(out_dir, 'labels.json'), 'w') as outfile:\n",
    "                json.dump(labels, outfile, indent=4)\n",
    "            \n",
    "            # One training step: train the model with one batch\n",
    "            def train_step(x_batch, y_batch):\n",
    "                if preentrenado:\n",
    "                    feed_dict = {\n",
    "                        cnn.input_x: x_batch,\n",
    "                        cnn.input_y: y_batch,\n",
    "                        cnn.dropout_keep_prob: params['dropout_keep_prob'],\n",
    "                        cnn.embedding_placeholder: embedding\n",
    "                    }\n",
    "                else:\n",
    "                    feed_dict = {\n",
    "                        cnn.input_x: x_batch,\n",
    "                        cnn.input_y: y_batch,\n",
    "                        cnn.dropout_keep_prob: params['dropout_keep_prob']\n",
    "                    }\n",
    "                _, step, loss, acc = sess.run([train_op, global_step, cnn.loss, cnn.accuracy], feed_dict)\n",
    "\n",
    "            # One evaluation step: evaluate the model with one batch\n",
    "            def dev_step(x_batch, y_batch):\n",
    "                if preentrenado:\n",
    "                    feed_dict = {\n",
    "                        cnn.input_x: x_batch,\n",
    "                        cnn.input_y: y_batch,\n",
    "                        cnn.dropout_keep_prob: 1.0,\n",
    "                        cnn.embedding_placeholder: embedding\n",
    "                    }\n",
    "                else:\n",
    "                    feed_dict = {\n",
    "                        cnn.input_x: x_batch,\n",
    "                        cnn.input_y: y_batch,\n",
    "                        cnn.dropout_keep_prob: 1.0\n",
    "                    }\n",
    "                step, loss, acc, num_correct = sess.run([global_step, cnn.loss, cnn.accuracy, cnn.num_correct], feed_dict)\n",
    "                #return num_correct\n",
    "                return acc\n",
    "\n",
    "            # Guardar el vocabulario para las predicciones\n",
    "            vocab_processor.save(os.path.join(out_dir, \"vocab\"))\n",
    "            \n",
    "            #Inicializa las variables del clasificador\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            # Obtiene los batches (lotes) para el entrenamiento\n",
    "            train_batches = batch_iter(list(zip(x_train, y_train)), params['batch_size'], params['num_epochs'])\n",
    "            best_accuracy, best_at_step = 0, 0\n",
    "\n",
    "            #Paso 6: entrenar el modelo de CNN con x_train y y_train (batch por batch)\n",
    "            logging.info(\" Inicio de entrenamiento\")\n",
    "            for train_batch in train_batches:\n",
    "                x_train_batch, y_train_batch = zip(*train_batch)\n",
    "                train_step(x_train_batch, y_train_batch)\n",
    "                current_step = tf.train.global_step(sess, global_step)\n",
    "\n",
    "                if current_step % params['evaluate_every'] == 0:\n",
    "                    logging.info(\" Etapa: {}\".format(current_step))\n",
    "                    #Paso 6.1: evaluar el modelo con x_dev y y_dev                  \n",
    "                    dev_accuracy = dev_step(x_dev, y_dev)\n",
    "                    \n",
    "                    logging.critical(' Exactitud en set de validación: {}'.format(dev_accuracy))\n",
    "\n",
    "                    if dev_accuracy >= best_accuracy:\n",
    "                        #Paso 6.2: Guardar el modelo si es el mejor basado en exactitud en el set de validación\n",
    "                        best_accuracy, best_at_step = dev_accuracy, current_step\n",
    "                        path = saver.save(sess, checkpoint_prefix, global_step=current_step)\n",
    "                        logging.critical(' Modelo guardado en {} en etapa {}'.format(path, best_at_step))\n",
    "                        logging.critical(' Mejor exactitud es {} en etapa {}'.format(best_accuracy, best_at_step))\n",
    "                        \n",
    "                        results = {\"acurracy\": \"{}\".format(best_accuracy)}\n",
    "                        \n",
    "                        with open(os.path.join(out_dir, \"resultados-{} {}.json\".format(current_step, round(best_accuracy * 100, 2))), 'w') as outfile:\n",
    "                            json.dump(results, outfile, indent=4)\n",
    "\n",
    "            #Paso 7: Predecir x_test\n",
    "            test_accuracy = dev_step(x_test, y_test)            \n",
    "            path = saver.save(sess, final_prefix, global_step=current_step)\n",
    "            logging.critical(' Modelo final guardado en {}'.format(path))\n",
    "            logging.critical(' Exactitud en set de pruebas es {} basado en el modelo final {}'.format(test_accuracy, path))\n",
    "            \n",
    "            results = {\"acurracy\": \"{}\".format(test_accuracy)}\n",
    "\n",
    "            with open(os.path.join(out_dir, \"resultados final {}.json\".format(round(test_accuracy * 100, 2))), 'w') as outfile:\n",
    "                json.dump(results, outfile, indent=4)\n",
    "            with open(os.path.join(out_dir, 'parametros.json'), 'w') as outfile:\n",
    "                json.dump(params, outfile, indent=4)\n",
    "            \n",
    "            checkpoint_file = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "            saver = tf.train.import_meta_graph(\"{}.meta\".format(checkpoint_file))\n",
    "            saver.restore(sess, checkpoint_file)\n",
    "            logging.critical(' Cargado el mejor modelo para hacer las pruebas: {}'.format(checkpoint_file))\n",
    "            test_accuracy = dev_step(x_test, y_test)\n",
    "            logging.critical(' Exactitud en set de pruebas es {} basado en el mejor modelo {}'.format(test_accuracy, path))\n",
    "            logging.critical(' Entrenamiento completado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root: Oración más larga tiene 47 palabras. Se agregan 5 para tener espacio de manipulación para nuevas oraciones\n",
      "INFO:root: Cargando vectores generados previamente\n",
      "INFO:root: x_train: 6255, x_dev: 696, x_test: 773\n",
      "INFO:root: y_train: 6255, y_dev: 696, y_test: 773\n",
      "INFO:root: Inicio de entrenamiento\n",
      "INFO:root: Etapa: 100\n",
      "CRITICAL:root: Exactitud en set de validación: 0.4597701132297516\n",
      "CRITICAL:root: Modelo guardado en D:\\respaldo joax\\UCR\\Maestria computacion\\2018-1\\NPL\\Deep learning\\trained_model_1528958572\\checkpoints\\model-100 en etapa 100\n",
      "CRITICAL:root: Mejor exactitud es 0.4597701132297516 en etapa 100\n",
      "INFO:root: Etapa: 200\n",
      "CRITICAL:root: Exactitud en set de validación: 0.47557470202445984\n",
      "CRITICAL:root: Modelo guardado en D:\\respaldo joax\\UCR\\Maestria computacion\\2018-1\\NPL\\Deep learning\\trained_model_1528958572\\checkpoints\\model-200 en etapa 200\n",
      "CRITICAL:root: Mejor exactitud es 0.47557470202445984 en etapa 200\n",
      "INFO:root: Etapa: 300\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5100574493408203\n",
      "CRITICAL:root: Modelo guardado en D:\\respaldo joax\\UCR\\Maestria computacion\\2018-1\\NPL\\Deep learning\\trained_model_1528958572\\checkpoints\\model-300 en etapa 300\n",
      "CRITICAL:root: Mejor exactitud es 0.5100574493408203 en etapa 300\n",
      "INFO:root: Etapa: 400\n",
      "CRITICAL:root: Exactitud en set de validación: 0.48706895112991333\n",
      "INFO:root: Etapa: 500\n",
      "CRITICAL:root: Exactitud en set de validación: 0.4885057508945465\n",
      "INFO:root: Etapa: 600\n",
      "CRITICAL:root: Exactitud en set de validación: 0.49425286054611206\n",
      "INFO:root: Etapa: 700\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5057471394538879\n",
      "INFO:root: Etapa: 800\n",
      "CRITICAL:root: Exactitud en set de validación: 0.4913793206214905\n",
      "INFO:root: Etapa: 900\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5086206793785095\n",
      "INFO:root: Etapa: 1000\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5143678188323975\n",
      "CRITICAL:root: Modelo guardado en D:\\respaldo joax\\UCR\\Maestria computacion\\2018-1\\NPL\\Deep learning\\trained_model_1528958572\\checkpoints\\model-1000 en etapa 1000\n",
      "CRITICAL:root: Mejor exactitud es 0.5143678188323975 en etapa 1000\n",
      "INFO:root: Etapa: 1100\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5201149582862854\n",
      "CRITICAL:root: Modelo guardado en D:\\respaldo joax\\UCR\\Maestria computacion\\2018-1\\NPL\\Deep learning\\trained_model_1528958572\\checkpoints\\model-1100 en etapa 1100\n",
      "CRITICAL:root: Mejor exactitud es 0.5201149582862854 en etapa 1100\n",
      "INFO:root: Etapa: 1200\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5301724076271057\n",
      "CRITICAL:root: Modelo guardado en D:\\respaldo joax\\UCR\\Maestria computacion\\2018-1\\NPL\\Deep learning\\trained_model_1528958572\\checkpoints\\model-1200 en etapa 1200\n",
      "CRITICAL:root: Mejor exactitud es 0.5301724076271057 en etapa 1200\n",
      "INFO:root: Etapa: 1300\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5100574493408203\n",
      "INFO:root: Etapa: 1400\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5301724076271057\n",
      "CRITICAL:root: Modelo guardado en D:\\respaldo joax\\UCR\\Maestria computacion\\2018-1\\NPL\\Deep learning\\trained_model_1528958572\\checkpoints\\model-1400 en etapa 1400\n",
      "CRITICAL:root: Mejor exactitud es 0.5301724076271057 en etapa 1400\n",
      "INFO:root: Etapa: 1500\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5215517282485962\n",
      "INFO:root: Etapa: 1600\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5359195470809937\n",
      "CRITICAL:root: Modelo guardado en D:\\respaldo joax\\UCR\\Maestria computacion\\2018-1\\NPL\\Deep learning\\trained_model_1528958572\\checkpoints\\model-1600 en etapa 1600\n",
      "CRITICAL:root: Mejor exactitud es 0.5359195470809937 en etapa 1600\n",
      "INFO:root: Etapa: 1700\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5373563170433044\n",
      "CRITICAL:root: Modelo guardado en D:\\respaldo joax\\UCR\\Maestria computacion\\2018-1\\NPL\\Deep learning\\trained_model_1528958572\\checkpoints\\model-1700 en etapa 1700\n",
      "CRITICAL:root: Mejor exactitud es 0.5373563170433044 en etapa 1700\n",
      "INFO:root: Etapa: 1800\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5258620977401733\n",
      "INFO:root: Etapa: 1900\n",
      "CRITICAL:root: Exactitud en set de validación: 0.540229856967926\n",
      "CRITICAL:root: Modelo guardado en D:\\respaldo joax\\UCR\\Maestria computacion\\2018-1\\NPL\\Deep learning\\trained_model_1528958572\\checkpoints\\model-1900 en etapa 1900\n",
      "CRITICAL:root: Mejor exactitud es 0.540229856967926 en etapa 1900\n",
      "INFO:root: Etapa: 2000\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5344827771186829\n",
      "INFO:root: Etapa: 2100\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5316091775894165\n",
      "INFO:root: Etapa: 2200\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5186781883239746\n",
      "INFO:root: Etapa: 2300\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5373563170433044\n",
      "INFO:root: Etapa: 2400\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5071839094161987\n",
      "INFO:root: Etapa: 2500\n",
      "CRITICAL:root: Exactitud en set de validación: 0.517241358757019\n",
      "INFO:root: Etapa: 2600\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5301724076271057\n",
      "INFO:root: Etapa: 2700\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5387930870056152\n",
      "INFO:root: Etapa: 2800\n",
      "CRITICAL:root: Exactitud en set de validación: 0.545976996421814\n",
      "CRITICAL:root: Modelo guardado en D:\\respaldo joax\\UCR\\Maestria computacion\\2018-1\\NPL\\Deep learning\\trained_model_1528958572\\checkpoints\\model-2800 en etapa 2800\n",
      "CRITICAL:root: Mejor exactitud es 0.545976996421814 en etapa 2800\n",
      "INFO:root: Etapa: 2900\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5287356376647949\n",
      "INFO:root: Etapa: 3000\n",
      "CRITICAL:root: Exactitud en set de validación: 0.517241358757019\n",
      "INFO:root: Etapa: 3100\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5244252681732178\n",
      "INFO:root: Etapa: 3200\n",
      "CRITICAL:root: Exactitud en set de validación: 0.517241358757019\n",
      "INFO:root: Etapa: 3300\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5301724076271057\n",
      "INFO:root: Etapa: 3400\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5201149582862854\n",
      "INFO:root: Etapa: 3500\n",
      "CRITICAL:root: Exactitud en set de validación: 0.522988498210907\n",
      "INFO:root: Etapa: 3600\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5431034564971924\n",
      "INFO:root: Etapa: 3700\n",
      "CRITICAL:root: Exactitud en set de validación: 0.517241358757019\n",
      "INFO:root: Etapa: 3800\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5186781883239746\n",
      "INFO:root: Etapa: 3900\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5158045887947083\n",
      "INFO:root: Etapa: 4000\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5301724076271057\n",
      "INFO:root: Etapa: 4100\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5387930870056152\n",
      "INFO:root: Etapa: 4200\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5272988677024841\n",
      "INFO:root: Etapa: 4300\n",
      "CRITICAL:root: Exactitud en set de validación: 0.540229856967926\n",
      "INFO:root: Etapa: 4400\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5445402264595032\n",
      "INFO:root: Etapa: 4500\n",
      "CRITICAL:root: Exactitud en set de validación: 0.522988498210907\n",
      "INFO:root: Etapa: 4600\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5158045887947083\n",
      "INFO:root: Etapa: 4700\n",
      "CRITICAL:root: Exactitud en set de validación: 0.540229856967926\n",
      "INFO:root: Etapa: 4800\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5272988677024841\n",
      "INFO:root: Etapa: 4900\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5359195470809937\n",
      "INFO:root: Etapa: 5000\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5359195470809937\n",
      "INFO:root: Etapa: 5100\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5387930870056152\n",
      "INFO:root: Etapa: 5200\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5086206793785095\n",
      "INFO:root: Etapa: 5300\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5373563170433044\n",
      "INFO:root: Etapa: 5400\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5244252681732178\n",
      "INFO:root: Etapa: 5500\n",
      "CRITICAL:root: Exactitud en set de validación: 0.545976996421814\n",
      "CRITICAL:root: Modelo guardado en D:\\respaldo joax\\UCR\\Maestria computacion\\2018-1\\NPL\\Deep learning\\trained_model_1528958572\\checkpoints\\model-5500 en etapa 5500\n",
      "CRITICAL:root: Mejor exactitud es 0.545976996421814 en etapa 5500\n",
      "INFO:root: Etapa: 5600\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5215517282485962\n",
      "INFO:root: Etapa: 5700\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5287356376647949\n",
      "INFO:root: Etapa: 5800\n",
      "CRITICAL:root: Exactitud en set de validación: 0.540229856967926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root: Etapa: 5900\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5445402264595032\n",
      "INFO:root: Etapa: 6000\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5301724076271057\n",
      "INFO:root: Etapa: 6100\n",
      "CRITICAL:root: Exactitud en set de validación: 0.545976996421814\n",
      "CRITICAL:root: Modelo guardado en D:\\respaldo joax\\UCR\\Maestria computacion\\2018-1\\NPL\\Deep learning\\trained_model_1528958572\\checkpoints\\model-6100 en etapa 6100\n",
      "CRITICAL:root: Mejor exactitud es 0.545976996421814 en etapa 6100\n",
      "INFO:root: Etapa: 6200\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5373563170433044\n",
      "INFO:root: Etapa: 6300\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5373563170433044\n",
      "INFO:root: Etapa: 6400\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5359195470809937\n",
      "INFO:root: Etapa: 6500\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5445402264595032\n",
      "INFO:root: Etapa: 6600\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5373563170433044\n",
      "INFO:root: Etapa: 6700\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5344827771186829\n",
      "INFO:root: Etapa: 6800\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5488505959510803\n",
      "CRITICAL:root: Modelo guardado en D:\\respaldo joax\\UCR\\Maestria computacion\\2018-1\\NPL\\Deep learning\\trained_model_1528958572\\checkpoints\\model-6800 en etapa 6800\n",
      "CRITICAL:root: Mejor exactitud es 0.5488505959510803 en etapa 6800\n",
      "INFO:root: Etapa: 6900\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5445402264595032\n",
      "INFO:root: Etapa: 7000\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5272988677024841\n",
      "INFO:root: Etapa: 7100\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5416666865348816\n",
      "INFO:root: Etapa: 7200\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5258620977401733\n",
      "INFO:root: Etapa: 7300\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5387930870056152\n",
      "INFO:root: Etapa: 7400\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5301724076271057\n",
      "INFO:root: Etapa: 7500\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5330459475517273\n",
      "INFO:root: Etapa: 7600\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5445402264595032\n",
      "INFO:root: Etapa: 7700\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5416666865348816\n",
      "INFO:root: Etapa: 7800\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5431034564971924\n",
      "INFO:root: Etapa: 7900\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5359195470809937\n",
      "INFO:root: Etapa: 8000\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5344827771186829\n",
      "INFO:root: Etapa: 8100\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5330459475517273\n",
      "INFO:root: Etapa: 8200\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5316091775894165\n",
      "INFO:root: Etapa: 8300\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5387930870056152\n",
      "INFO:root: Etapa: 8400\n",
      "CRITICAL:root: Exactitud en set de validación: 0.540229856967926\n",
      "INFO:root: Etapa: 8500\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5416666865348816\n",
      "INFO:root: Etapa: 8600\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5186781883239746\n",
      "INFO:root: Etapa: 8700\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5474137663841248\n",
      "INFO:root: Etapa: 8800\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5416666865348816\n",
      "INFO:root: Etapa: 8900\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5431034564971924\n",
      "INFO:root: Etapa: 9000\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5416666865348816\n",
      "INFO:root: Etapa: 9100\n",
      "CRITICAL:root: Exactitud en set de validación: 0.540229856967926\n",
      "INFO:root: Etapa: 9200\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5316091775894165\n",
      "INFO:root: Etapa: 9300\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5474137663841248\n",
      "INFO:root: Etapa: 9400\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5416666865348816\n",
      "INFO:root: Etapa: 9500\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5201149582862854\n",
      "INFO:root: Etapa: 9600\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5272988677024841\n",
      "INFO:root: Etapa: 9700\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5387930870056152\n",
      "INFO:root: Etapa: 9800\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5416666865348816\n",
      "INFO:root: Etapa: 9900\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5373563170433044\n",
      "INFO:root: Etapa: 10000\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5344827771186829\n",
      "INFO:root: Etapa: 10100\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5272988677024841\n",
      "INFO:root: Etapa: 10200\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5344827771186829\n",
      "INFO:root: Etapa: 10300\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5301724076271057\n",
      "INFO:root: Etapa: 10400\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5359195470809937\n",
      "INFO:root: Etapa: 10500\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5373563170433044\n",
      "INFO:root: Etapa: 10600\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5244252681732178\n",
      "INFO:root: Etapa: 10700\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5158045887947083\n",
      "INFO:root: Etapa: 10800\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5431034564971924\n",
      "INFO:root: Etapa: 10900\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5272988677024841\n",
      "INFO:root: Etapa: 11000\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5272988677024841\n",
      "INFO:root: Etapa: 11100\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5416666865348816\n",
      "INFO:root: Etapa: 11200\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5373563170433044\n",
      "INFO:root: Etapa: 11300\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5330459475517273\n",
      "INFO:root: Etapa: 11400\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5387930870056152\n",
      "INFO:root: Etapa: 11500\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5373563170433044\n",
      "INFO:root: Etapa: 11600\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5359195470809937\n",
      "INFO:root: Etapa: 11700\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5316091775894165\n",
      "INFO:root: Etapa: 11800\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5373563170433044\n",
      "INFO:root: Etapa: 11900\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5359195470809937\n",
      "INFO:root: Etapa: 12000\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5502873659133911\n",
      "CRITICAL:root: Modelo guardado en D:\\respaldo joax\\UCR\\Maestria computacion\\2018-1\\NPL\\Deep learning\\trained_model_1528958572\\checkpoints\\model-12000 en etapa 12000\n",
      "CRITICAL:root: Mejor exactitud es 0.5502873659133911 en etapa 12000\n",
      "INFO:root: Etapa: 12100\n",
      "CRITICAL:root: Exactitud en set de validación: 0.540229856967926\n",
      "INFO:root: Etapa: 12200\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5416666865348816\n",
      "INFO:root: Etapa: 12300\n",
      "CRITICAL:root: Exactitud en set de validación: 0.540229856967926\n",
      "INFO:root: Etapa: 12400\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5431034564971924\n",
      "INFO:root: Etapa: 12500\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5359195470809937\n",
      "INFO:root: Etapa: 12600\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5373563170433044\n",
      "INFO:root: Etapa: 12700\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5301724076271057\n",
      "INFO:root: Etapa: 12800\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5316091775894165\n",
      "INFO:root: Etapa: 12900\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5445402264595032\n",
      "INFO:root: Etapa: 13000\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5431034564971924\n",
      "INFO:root: Etapa: 13100\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5416666865348816\n",
      "INFO:root: Etapa: 13200\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5416666865348816\n",
      "INFO:root: Etapa: 13300\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5215517282485962\n",
      "INFO:root: Etapa: 13400\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5416666865348816\n",
      "INFO:root: Etapa: 13500\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5416666865348816\n",
      "INFO:root: Etapa: 13600\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5531609058380127\n",
      "CRITICAL:root: Modelo guardado en D:\\respaldo joax\\UCR\\Maestria computacion\\2018-1\\NPL\\Deep learning\\trained_model_1528958572\\checkpoints\\model-13600 en etapa 13600\n",
      "CRITICAL:root: Mejor exactitud es 0.5531609058380127 en etapa 13600\n",
      "INFO:root: Etapa: 13700\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5531609058380127\n",
      "CRITICAL:root: Modelo guardado en D:\\respaldo joax\\UCR\\Maestria computacion\\2018-1\\NPL\\Deep learning\\trained_model_1528958572\\checkpoints\\model-13700 en etapa 13700\n",
      "CRITICAL:root: Mejor exactitud es 0.5531609058380127 en etapa 13700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root: Etapa: 13800\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5316091775894165\n",
      "INFO:root: Etapa: 13900\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5517241358757019\n",
      "INFO:root: Etapa: 14000\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5445402264595032\n",
      "INFO:root: Etapa: 14100\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5531609058380127\n",
      "CRITICAL:root: Modelo guardado en D:\\respaldo joax\\UCR\\Maestria computacion\\2018-1\\NPL\\Deep learning\\trained_model_1528958572\\checkpoints\\model-14100 en etapa 14100\n",
      "CRITICAL:root: Mejor exactitud es 0.5531609058380127 en etapa 14100\n",
      "INFO:root: Etapa: 14200\n",
      "CRITICAL:root: Exactitud en set de validación: 0.522988498210907\n",
      "INFO:root: Etapa: 14300\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5416666865348816\n",
      "INFO:root: Etapa: 14400\n",
      "CRITICAL:root: Exactitud en set de validación: 0.545976996421814\n",
      "INFO:root: Etapa: 14500\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5215517282485962\n",
      "INFO:root: Etapa: 14600\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5502873659133911\n",
      "INFO:root: Etapa: 14700\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5416666865348816\n",
      "INFO:root: Etapa: 14800\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5416666865348816\n",
      "INFO:root: Etapa: 14900\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5531609058380127\n",
      "CRITICAL:root: Modelo guardado en D:\\respaldo joax\\UCR\\Maestria computacion\\2018-1\\NPL\\Deep learning\\trained_model_1528958572\\checkpoints\\model-14900 en etapa 14900\n",
      "CRITICAL:root: Mejor exactitud es 0.5531609058380127 en etapa 14900\n",
      "INFO:root: Etapa: 15000\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5416666865348816\n",
      "INFO:root: Etapa: 15100\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5359195470809937\n",
      "INFO:root: Etapa: 15200\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5359195470809937\n",
      "INFO:root: Etapa: 15300\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5316091775894165\n",
      "INFO:root: Etapa: 15400\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5416666865348816\n",
      "INFO:root: Etapa: 15500\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5474137663841248\n",
      "INFO:root: Etapa: 15600\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5517241358757019\n",
      "INFO:root: Etapa: 15700\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5517241358757019\n",
      "INFO:root: Etapa: 15800\n",
      "CRITICAL:root: Exactitud en set de validación: 0.545976996421814\n",
      "INFO:root: Etapa: 15900\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5617815852165222\n",
      "CRITICAL:root: Modelo guardado en D:\\respaldo joax\\UCR\\Maestria computacion\\2018-1\\NPL\\Deep learning\\trained_model_1528958572\\checkpoints\\model-15900 en etapa 15900\n",
      "CRITICAL:root: Mejor exactitud es 0.5617815852165222 en etapa 15900\n",
      "INFO:root: Etapa: 16000\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5387930870056152\n",
      "INFO:root: Etapa: 16100\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5474137663841248\n",
      "INFO:root: Etapa: 16200\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5416666865348816\n",
      "INFO:root: Etapa: 16300\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5316091775894165\n",
      "INFO:root: Etapa: 16400\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5445402264595032\n",
      "INFO:root: Etapa: 16500\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5545976758003235\n",
      "INFO:root: Etapa: 16600\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5474137663841248\n",
      "INFO:root: Etapa: 16700\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5201149582862854\n",
      "INFO:root: Etapa: 16800\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5488505959510803\n",
      "INFO:root: Etapa: 16900\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5416666865348816\n",
      "INFO:root: Etapa: 17000\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5373563170433044\n",
      "INFO:root: Etapa: 17100\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5344827771186829\n",
      "INFO:root: Etapa: 17200\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5431034564971924\n",
      "INFO:root: Etapa: 17300\n",
      "CRITICAL:root: Exactitud en set de validación: 0.540229856967926\n",
      "INFO:root: Etapa: 17400\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5431034564971924\n",
      "INFO:root: Etapa: 17500\n",
      "CRITICAL:root: Exactitud en set de validación: 0.540229856967926\n",
      "INFO:root: Etapa: 17600\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5344827771186829\n",
      "INFO:root: Etapa: 17700\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5344827771186829\n",
      "INFO:root: Etapa: 17800\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5416666865348816\n",
      "INFO:root: Etapa: 17900\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5287356376647949\n",
      "INFO:root: Etapa: 18000\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5502873659133911\n",
      "INFO:root: Etapa: 18100\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5488505959510803\n",
      "INFO:root: Etapa: 18200\n",
      "CRITICAL:root: Exactitud en set de validación: 0.540229856967926\n",
      "INFO:root: Etapa: 18300\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5445402264595032\n",
      "INFO:root: Etapa: 18400\n",
      "CRITICAL:root: Exactitud en set de validación: 0.545976996421814\n",
      "INFO:root: Etapa: 18500\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5488505959510803\n",
      "INFO:root: Etapa: 18600\n",
      "CRITICAL:root: Exactitud en set de validación: 0.545976996421814\n",
      "INFO:root: Etapa: 18700\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5387930870056152\n",
      "INFO:root: Etapa: 18800\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5502873659133911\n",
      "INFO:root: Etapa: 18900\n",
      "CRITICAL:root: Exactitud en set de validación: 0.540229856967926\n",
      "INFO:root: Etapa: 19000\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5517241358757019\n",
      "INFO:root: Etapa: 19100\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5344827771186829\n",
      "INFO:root: Etapa: 19200\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5531609058380127\n",
      "INFO:root: Etapa: 19300\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5316091775894165\n",
      "INFO:root: Etapa: 19400\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5387930870056152\n",
      "INFO:root: Etapa: 19500\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5330459475517273\n",
      "INFO:root: Etapa: 19600\n",
      "CRITICAL:root: Exactitud en set de validación: 0.5373563170433044\n",
      "CRITICAL:root: Modelo final guardado en D:\\respaldo joax\\UCR\\Maestria computacion\\2018-1\\NPL\\Deep learning\\trained_model_1528958572\\checkpoints\\model-19600\n",
      "CRITICAL:root: Exactitud en set de pruebas es 0.5498059391975403 basado en el modelo final D:\\respaldo joax\\UCR\\Maestria computacion\\2018-1\\NPL\\Deep learning\\trained_model_1528958572\\checkpoints\\model-19600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from D:\\respaldo joax\\UCR\\Maestria computacion\\2018-1\\NPL\\Deep learning\\trained_model_1528958572\\checkpoints\\model-19600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from D:\\respaldo joax\\UCR\\Maestria computacion\\2018-1\\NPL\\Deep learning\\trained_model_1528958572\\checkpoints\\model-19600\n",
      "CRITICAL:root: Cargado el mejor modelo para hacer las pruebas: D:\\respaldo joax\\UCR\\Maestria computacion\\2018-1\\NPL\\Deep learning\\trained_model_1528958572\\checkpoints\\model-19600\n",
      "CRITICAL:root: Exactitud en set de pruebas es 0.5498059391975403 basado en el mejor modelo D:\\respaldo joax\\UCR\\Maestria computacion\\2018-1\\NPL\\Deep learning\\trained_model_1528958572\\checkpoints\\model-19600\n",
      "CRITICAL:root: Entrenamiento completado\n"
     ]
    }
   ],
   "source": [
    "train_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
