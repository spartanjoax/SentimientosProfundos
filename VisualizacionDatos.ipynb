{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualización de los datos obtenidos\n",
    "\n",
    "Se van a contar las palabras y visualizar la ocurrencia de las mismas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Texto</th>\n",
       "      <th>Polaridad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>salgo de #veotv que día más largoooooo</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@pauladelasheras no te libraras de ayudar meno...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@marodriguezb gracias mar</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>off pensando en el regalito sinde la que se va...</td>\n",
       "      <td>N+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>conozco a alguien q es adicto al drama! ja ja ...</td>\n",
       "      <td>P+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Texto Polaridad\n",
       "0             salgo de #veotv que día más largoooooo      NONE\n",
       "1  @pauladelasheras no te libraras de ayudar meno...       NEU\n",
       "2                          @marodriguezb gracias mar         P\n",
       "3  off pensando en el regalito sinde la que se va...        N+\n",
       "4  conozco a alguien q es adicto al drama! ja ja ...        P+"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Importar el archivo con los tweets pre procesados (limpios)\n",
    "csv = 'tweets_limpios.csv'\n",
    "my_df = pd.read_csv(csv,index_col=0)\n",
    "my_df.head()\n",
    "\n",
    "#Imprimir las primeras líneas del archivo para validar una carga correcta\n",
    "my_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uso de CountVectorizer\n",
    "CountVectorizer convierte los comentarios en una matriz en la que cada palabra es una columna cuyo valor es el número de veces que aparece en cada tweet.\n",
    "\n",
    "Esta parte añade procesamiento obtenido de https://new.pybonacci.org/2015/11/24/como-hacer-analisis-de-sentimiento-en-espanol-2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\joax\\anaconda2\\lib\\site-packages\\ipykernel_launcher.py:32: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12447"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Descargar las stopwords y punkt primero con el downloader de nltk\n",
    "#En la consola de Anaconda, correr: python -m nltk.downloader stopwords\n",
    "#En la consola de Anaconda, correr: python -m nltk.downloader punkt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.data import load\n",
    "from nltk.stem import SnowballStemmer\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Carga los stopwords de español y el stemmer\n",
    "spanish_stopwords = stopwords.words('spanish')\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "\n",
    "#Se crea la lista de puntuación para eliminar de las frecuencias\n",
    "non_words = list(punctuation)\n",
    "non_words.extend(['¿', '¡'])\n",
    "non_words.extend(map(str,range(10)))\n",
    "\n",
    "#Método que obtiene el lema de las palabras\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    #Para cada palabra, obtenga el lema\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "#Método que tokeniza los tweets y le obtiene el lema a cada token\n",
    "def tokenize(text):\n",
    "    #Se quitan las puntuaciones\n",
    "    text = ''.join([c for c in text if c not in non_words])\n",
    "    #Se obtienen los tokens\n",
    "    tokens =  word_tokenize(text)\n",
    "\n",
    "    # stem\n",
    "    try:\n",
    "        stems = stem_tokens(tokens, stemmer)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(text)\n",
    "        stems = ['']\n",
    "    return stems\n",
    "\n",
    "#Se usa CountVectorizer para contar la frecuencia de las palabras\n",
    "cvec = CountVectorizer(\n",
    "                analyzer = 'word',\n",
    "                tokenizer = tokenize,\n",
    "                lowercase = True,\n",
    "                stop_words = spanish_stopwords)\n",
    "cvec.fit(my_df.Texto)\n",
    "len(cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\joax\\anaconda2\\lib\\site-packages\\ipykernel_launcher.py:32: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    }
   ],
   "source": [
    "#Generar matrices\n",
    "none_doc_matrix = cvec.transform(my_df[my_df.Polaridad == \"NONE\"].Texto)\n",
    "pos_doc_matrix = cvec.transform(my_df[my_df.Polaridad == \"P\"].Texto)\n",
    "neg_doc_matrix = cvec.transform(my_df[my_df.Polaridad == \"N\"].Texto)\n",
    "posmas_doc_matrix = cvec.transform(my_df[my_df.Polaridad == \"P+\"].Texto)\n",
    "negmas_doc_matrix = cvec.transform(my_df[my_df.Polaridad == \"N+\"].Texto)\n",
    "\n",
    "none_tf = np.sum(none_doc_matrix,axis=0)\n",
    "neu_tf = np.sum(neu_doc_matrix,axis=0)\n",
    "neg_tf = np.sum(neg_doc_matrix,axis=0)\n",
    "pos_tf = np.sum(pos_doc_matrix,axis=0)\n",
    "negmas_tf = np.sum(negmas_doc_matrix,axis=0)\n",
    "posmas_tf = np.sum(posmas_doc_matrix,axis=0)\n",
    "\n",
    "none = np.squeeze(np.asarray(none_tf))\n",
    "neu = np.squeeze(np.asarray(neu_tf))\n",
    "neg = np.squeeze(np.asarray(neg_tf))\n",
    "pos = np.squeeze(np.asarray(pos_tf))\n",
    "negmas = np.squeeze(np.asarray(negmas_tf))\n",
    "posmas = np.squeeze(np.asarray(posmas_tf))\n",
    "\n",
    "term_freq_df = pd.DataFrame([none,neu,neg,pos,negmas,posmas],columns=cvec.get_feature_names()).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>None</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Negativo</th>\n",
       "      <th>Positivo</th>\n",
       "      <th>Negativo+</th>\n",
       "      <th>Positivo+</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>xurlx</th>\n",
       "      <td>763</td>\n",
       "      <td>159</td>\n",
       "      <td>384</td>\n",
       "      <td>485</td>\n",
       "      <td>242</td>\n",
       "      <td>510</td>\n",
       "      <td>2543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xnumx</th>\n",
       "      <td>303</td>\n",
       "      <td>138</td>\n",
       "      <td>278</td>\n",
       "      <td>220</td>\n",
       "      <td>271</td>\n",
       "      <td>305</td>\n",
       "      <td>1515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>par</th>\n",
       "      <td>141</td>\n",
       "      <td>109</td>\n",
       "      <td>194</td>\n",
       "      <td>220</td>\n",
       "      <td>179</td>\n",
       "      <td>258</td>\n",
       "      <td>1101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rt</th>\n",
       "      <td>95</td>\n",
       "      <td>40</td>\n",
       "      <td>82</td>\n",
       "      <td>150</td>\n",
       "      <td>35</td>\n",
       "      <td>200</td>\n",
       "      <td>602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q</th>\n",
       "      <td>44</td>\n",
       "      <td>72</td>\n",
       "      <td>181</td>\n",
       "      <td>63</td>\n",
       "      <td>103</td>\n",
       "      <td>99</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tod</th>\n",
       "      <td>50</td>\n",
       "      <td>38</td>\n",
       "      <td>69</td>\n",
       "      <td>93</td>\n",
       "      <td>47</td>\n",
       "      <td>205</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mas</th>\n",
       "      <td>43</td>\n",
       "      <td>52</td>\n",
       "      <td>96</td>\n",
       "      <td>62</td>\n",
       "      <td>86</td>\n",
       "      <td>141</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>com</th>\n",
       "      <td>58</td>\n",
       "      <td>53</td>\n",
       "      <td>104</td>\n",
       "      <td>70</td>\n",
       "      <td>83</td>\n",
       "      <td>87</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buen</th>\n",
       "      <td>61</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>114</td>\n",
       "      <td>9</td>\n",
       "      <td>197</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>95</td>\n",
       "      <td>66</td>\n",
       "      <td>107</td>\n",
       "      <td>93</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       None  Neutral  Negativo  Positivo  Negativo+  Positivo+  Total\n",
       "xurlx   763      159       384       485        242        510   2543\n",
       "xnumx   303      138       278       220        271        305   1515\n",
       "par     141      109       194       220        179        258   1101\n",
       "rt       95       40        82       150         35        200    602\n",
       "q        44       72       181        63        103         99    562\n",
       "tod      50       38        69        93         47        205    502\n",
       "mas      43       52        96        62         86        141    480\n",
       "com      58       53       104        70         83         87    455\n",
       "buen     61       42        30       114          9        197    453\n",
       "d        40       38        95        66        107         93    439"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tabular las matrices para poder ver las palabras con mayor repetición\n",
    "term_freq_df.columns = ['None', 'Neutral', 'Negativo', 'Positivo', 'Negativo+', 'Positivo+']\n",
    "term_freq_df['Total'] = term_freq_df['None'] + term_freq_df['Neutral']+term_freq_df['Negativo'] + term_freq_df['Positivo']+term_freq_df['Negativo+'] + term_freq_df['Positivo+']\n",
    "term_freq_df.sort_values(by='Total', ascending=False).iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
