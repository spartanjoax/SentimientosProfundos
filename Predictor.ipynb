{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictor basado en CNN\n",
    "Basado en https://github.com/satojkovic/cnn-text-classification-tf/tree/use_fasttext y https://github.com/jiegzhan/multi-class-text-classification-cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se importa el texto a predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[':-)', ':-))', '(-:', '((-:', ':)', ':))', '(:', '((:', ':-]', '[-:']\n",
      "[':-(', ':(', ':-c', ':c', ':-<', ':<', ':-[', ':[', ':-||', '>:[']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "from tensorflow.contrib import learn\n",
    "from Preprocesador import Preprocesador\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "carpetaModeloEntrenado = 'trained_model_1529315717'\n",
    "preprocesador = Preprocesador()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correr este si se va a cargar un CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvPrueba = 'general-tweets-test1k.csv'\n",
    "\n",
    "#Definir el nombre de las columnas del archivo\n",
    "cols = ['id','usuario','Texto','Fecha','Idioma','Polaridad']\n",
    "\n",
    "#Importar el archivo en memoria \n",
    "#Se indica que no tiene encabezados\n",
    "#Se usan los nombres definidos anteriormente los nombres de las columnas\n",
    "df = pd.read_csv(csvPrueba,header=None, names=cols)\n",
    "\n",
    "#Imprimir las primeras líneas del archivo para validar una carga correcta\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correr este si se va a cargar un XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>usuario</th>\n",
       "      <th>Texto</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Idioma</th>\n",
       "      <th>Polaridad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>770567971701940224</td>\n",
       "      <td>wikimiscojones</td>\n",
       "      <td>@LonelySoad mientras que no te pillen la prime...</td>\n",
       "      <td>2016-08-30 10:24:55</td>\n",
       "      <td>es</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>770503386789711872</td>\n",
       "      <td>HLF_Metr4spt</td>\n",
       "      <td>@ceemeese ya era hora de volver al csgo y deja...</td>\n",
       "      <td>2016-08-30 06:08:17</td>\n",
       "      <td>es</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>770502863017635840</td>\n",
       "      <td>AVazquez_C</td>\n",
       "      <td>@mireiaescribano justo cuando se terminan las ...</td>\n",
       "      <td>2016-08-30 06:06:12</td>\n",
       "      <td>es</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>770599972102348800</td>\n",
       "      <td>minniecris</td>\n",
       "      <td>@LuisMartinez22_ pensba q iba a hacer @wxplosi...</td>\n",
       "      <td>2016-08-30 12:32:05</td>\n",
       "      <td>es</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>770599962216390656</td>\n",
       "      <td>VI_Lelouch</td>\n",
       "      <td>@Vic_Phantomhive Si lo encuentro, sin compañer...</td>\n",
       "      <td>2016-08-30 12:32:02</td>\n",
       "      <td>es</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id         usuario  \\\n",
       "0  770567971701940224  wikimiscojones   \n",
       "1  770503386789711872    HLF_Metr4spt   \n",
       "2  770502863017635840      AVazquez_C   \n",
       "3  770599972102348800      minniecris   \n",
       "4  770599962216390656      VI_Lelouch   \n",
       "\n",
       "                                               Texto                Fecha  \\\n",
       "0  @LonelySoad mientras que no te pillen la prime...  2016-08-30 10:24:55   \n",
       "1  @ceemeese ya era hora de volver al csgo y deja...  2016-08-30 06:08:17   \n",
       "2  @mireiaescribano justo cuando se terminan las ...  2016-08-30 06:06:12   \n",
       "3  @LuisMartinez22_ pensba q iba a hacer @wxplosi...  2016-08-30 12:32:05   \n",
       "4  @Vic_Phantomhive Si lo encuentro, sin compañer...  2016-08-30 12:32:02   \n",
       "\n",
       "  Idioma Polaridad  \n",
       "0     es      None  \n",
       "1     es      None  \n",
       "2     es      None  \n",
       "3     es      None  \n",
       "4     es      None  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xmlPrueba = 'TASS2017_T1_test.xml'\n",
    "\n",
    "#Definir el nombre de las columnas del archivo\n",
    "cols = ['id','usuario','Texto','Fecha','Idioma','Polaridad']\n",
    "df = pd.DataFrame(columns=cols)\n",
    "\n",
    "def getvalueofnode(node):\n",
    "    \"\"\" return node text or None \"\"\"\n",
    "    return node.text if node is not None else None\n",
    "        \n",
    "#Cargar el xml y convertirlo a un DataFrame\n",
    "etree = ET.parse(xmlPrueba) #create an ElementTree object \n",
    "for node in etree.getroot():\n",
    "        tweetId = node.find('tweetid')\n",
    "        user = node.find('user')\n",
    "        content = node.find('content')\n",
    "        date = node.find('date')\n",
    "        lang = node.find('lang')\n",
    "        polarity = node.find('sentiment/polarity/value')\n",
    "        \n",
    "        df = df.append(\n",
    "            pd.Series([getvalueofnode(tweetId), getvalueofnode(user), getvalueofnode(content),\n",
    "                       getvalueofnode(date), getvalueofnode(lang), getvalueofnode(polarity)], \n",
    "                      index=cols), ignore_index=True)\n",
    "\n",
    "#Imprimir las primeras líneas del archivo para validar una carga correcta\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se va a pre-procesar el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre procesando tweets...\n",
      "\n",
      "1000 de 1899 tweets procesados\n",
      "Pre procesamiento completado\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>usuario</th>\n",
       "      <th>Texto</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Idioma</th>\n",
       "      <th>Polaridad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>770567971701940224</td>\n",
       "      <td>wikimiscojones</td>\n",
       "      <td>lonelysoad mientras que no te pillen la primer...</td>\n",
       "      <td>2016-08-30 10:24:55</td>\n",
       "      <td>es</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>770503386789711872</td>\n",
       "      <td>HLF_Metr4spt</td>\n",
       "      <td>ceemeese ya era hora de volver al csgo y dejar...</td>\n",
       "      <td>2016-08-30 06:08:17</td>\n",
       "      <td>es</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>770502863017635840</td>\n",
       "      <td>AVazquez_C</td>\n",
       "      <td>mireiaescribano justo cuando se terminan las f...</td>\n",
       "      <td>2016-08-30 06:06:12</td>\n",
       "      <td>es</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>770599972102348800</td>\n",
       "      <td>minniecris</td>\n",
       "      <td>luismartinezxnumx pensba q iba a hacer wxplosi...</td>\n",
       "      <td>2016-08-30 12:32:05</td>\n",
       "      <td>es</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>770599962216390656</td>\n",
       "      <td>VI_Lelouch</td>\n",
       "      <td>vicphantomhive si lo encuentro sin compañeros ...</td>\n",
       "      <td>2016-08-30 12:32:02</td>\n",
       "      <td>es</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id         usuario  \\\n",
       "0  770567971701940224  wikimiscojones   \n",
       "1  770503386789711872    HLF_Metr4spt   \n",
       "2  770502863017635840      AVazquez_C   \n",
       "3  770599972102348800      minniecris   \n",
       "4  770599962216390656      VI_Lelouch   \n",
       "\n",
       "                                               Texto                Fecha  \\\n",
       "0  lonelysoad mientras que no te pillen la primer...  2016-08-30 10:24:55   \n",
       "1  ceemeese ya era hora de volver al csgo y dejar...  2016-08-30 06:08:17   \n",
       "2  mireiaescribano justo cuando se terminan las f...  2016-08-30 06:06:12   \n",
       "3  luismartinezxnumx pensba q iba a hacer wxplosi...  2016-08-30 12:32:05   \n",
       "4  vicphantomhive si lo encuentro sin compañeros ...  2016-08-30 12:32:02   \n",
       "\n",
       "  Idioma Polaridad  \n",
       "0     es      None  \n",
       "1     es      None  \n",
       "2     es      None  \n",
       "3     es      None  \n",
       "4     es      None  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = df.copy()\n",
    "\n",
    "print (\"Pre procesando tweets...\\n\")\n",
    "clean_tweet_texts = []\n",
    "for i in range(df.Texto.count()):\n",
    "    if( (i+1)%1000 == 0 ):\n",
    "        print(\"%d de %d tweets procesados\" % ( i+1, df.Texto.count() ))\n",
    "    clean_tweet_texts.append(preprocesador.tweetCleaner(str(df['Texto'][i])))\n",
    "print (\"Pre procesamiento completado\")\n",
    "\n",
    "clean_df['Texto'] = clean_tweet_texts\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iter(data, batch_size, num_epochs, shuffle=True):\n",
    "    \"\"\"\n",
    "    Generates a batch iterator for a dataset.\n",
    "    \"\"\"\n",
    "    data = np.array(data)\n",
    "    data_size = len(data)\n",
    "    num_batches_per_epoch = int((len(data)-1)/batch_size) + 1\n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle the data at each epoch\n",
    "        if shuffle:\n",
    "            shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "            shuffled_data = data[shuffle_indices]\n",
    "        else:\n",
    "            shuffled_data = data\n",
    "        for batch_num in range(num_batches_per_epoch):\n",
    "            start_index = batch_num * batch_size\n",
    "            end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "            yield shuffled_data[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_unseen_data():\n",
    "    \"\"\"Step 0: load trained model and parameters\"\"\"\n",
    "    checkpoint_dir = carpetaModeloEntrenado\n",
    "    if not checkpoint_dir.endswith('/'):\n",
    "        checkpoint_dir += '/'\n",
    "    checkpoint_file = tf.train.latest_checkpoint(checkpoint_dir + 'checkpoints')\n",
    "    out_dir = os.path.abspath(os.path.join(os.path.curdir, carpetaModeloEntrenado))\n",
    "    params = json.loads(open(os.path.join(out_dir, 'parametros.json')).read())\n",
    "    logging.critical('Loaded the trained model: {}'.format(checkpoint_file))\n",
    "\n",
    "    \"\"\"Step 1: load data for prediction\"\"\"\n",
    "    test_file = sys.argv[2]\n",
    "    test_examples = json.loads(open(test_file).read())\n",
    "\n",
    "    # labels.json was saved during training, and it has to be loaded during prediction\n",
    "    labels = json.loads(open(os.path.join(out_dir, 'labels.json')).read())\n",
    "    one_hot = np.zeros((len(labels), len(labels)), int)\n",
    "    np.fill_diagonal(one_hot, 1)\n",
    "    label_dict = dict(zip(labels, one_hot))\n",
    "\n",
    "    x_test = [str(example) for example in clean_df.Texto]\n",
    "    logging.info('The number of x_test: {}'.format(len(x_test)))\n",
    "\n",
    "    y_test = None\n",
    "\n",
    "    vocab_path = os.path.join(checkpoint_dir, \"vocab\")\n",
    "    vocab_processor = learn.preprocessing.VocabularyProcessor.restore(vocab_path)\n",
    "    x_test = np.array(list(vocab_processor.transform(x_test)))\n",
    "    my_file = Path(\"fasttext_vocabulario.dat\")\n",
    "    preentrenado = my_file.is_file()\n",
    "    if preentrenado:\n",
    "        print('Load pre-trained word vectors')\n",
    "        embedding = np.load('fasttext_embeddings.npy')\n",
    "\n",
    "    \"\"\"Step 2: compute the predictions\"\"\"\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        session_conf = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)\n",
    "        sess = tf.Session(config=session_conf)\n",
    "\n",
    "        with sess.as_default():\n",
    "            saver = tf.train.import_meta_graph(\"{}.meta\".format(checkpoint_file))\n",
    "            saver.restore(sess, checkpoint_file)\n",
    "\n",
    "            input_x = graph.get_operation_by_name(\"input_x\").outputs[0]\n",
    "            dropout_keep_prob = graph.get_operation_by_name(\"dropout_keep_prob\").outputs[0]\n",
    "            embedding_placeholder = graph.get_operation_by_name('embedding/pre_trained').outputs[0]\n",
    "            predictions = graph.get_operation_by_name(\"output/predictions\").outputs[0]\n",
    "\n",
    "            batches = batch_iter(list(x_test), params['batch_size'], 1, shuffle=False)\n",
    "            all_predictions = []\n",
    "            for x_test_batch in batches:\n",
    "                batch_predictions = sess.run(predictions, {input_x: x_test_batch, embedding_placeholder: embedding, dropout_keep_prob: 1.0})\n",
    "                all_predictions = np.concatenate([all_predictions, batch_predictions])\n",
    "\n",
    "    if y_test is not None:\n",
    "        y_test = np.argmax(y_test, axis=1)\n",
    "        correct_predictions = sum(all_predictions == y_test)\n",
    "\n",
    "        logging.critical('The accuracy is: {}'.format(correct_predictions / float(len(y_test))))\n",
    "        logging.critical('The prediction is complete')\n",
    "\n",
    "    # Save the actual labels back to file\n",
    "    actual_labels = [labels[int(prediction)] for prediction in all_predictions]\n",
    "    \n",
    "    for i in range(df.Texto.count()):\n",
    "        df.Polaridad[i] = actual_labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:Loaded the trained model: D:\\respaldo joax\\UCR\\Maestria computacion\\2018-1\\NPL\\Deep learning\\trained_model_1529315717\\checkpoints\\model-5600\n",
      "INFO:root:The number of x_test: 1899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pre-trained word vectors\n",
      "INFO:tensorflow:Restoring parameters from D:\\respaldo joax\\UCR\\Maestria computacion\\2018-1\\NPL\\Deep learning\\trained_model_1529315717\\checkpoints\\model-5600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from D:\\respaldo joax\\UCR\\Maestria computacion\\2018-1\\NPL\\Deep learning\\trained_model_1529315717\\checkpoints\\model-5600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>usuario</th>\n",
       "      <th>Texto</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Idioma</th>\n",
       "      <th>Polaridad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>770567971701940224</td>\n",
       "      <td>wikimiscojones</td>\n",
       "      <td>@LonelySoad mientras que no te pillen la prime...</td>\n",
       "      <td>2016-08-30 10:24:55</td>\n",
       "      <td>es</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>770503386789711872</td>\n",
       "      <td>HLF_Metr4spt</td>\n",
       "      <td>@ceemeese ya era hora de volver al csgo y deja...</td>\n",
       "      <td>2016-08-30 06:08:17</td>\n",
       "      <td>es</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>770502863017635840</td>\n",
       "      <td>AVazquez_C</td>\n",
       "      <td>@mireiaescribano justo cuando se terminan las ...</td>\n",
       "      <td>2016-08-30 06:06:12</td>\n",
       "      <td>es</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>770599972102348800</td>\n",
       "      <td>minniecris</td>\n",
       "      <td>@LuisMartinez22_ pensba q iba a hacer @wxplosi...</td>\n",
       "      <td>2016-08-30 12:32:05</td>\n",
       "      <td>es</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>770599962216390656</td>\n",
       "      <td>VI_Lelouch</td>\n",
       "      <td>@Vic_Phantomhive Si lo encuentro, sin compañer...</td>\n",
       "      <td>2016-08-30 12:32:02</td>\n",
       "      <td>es</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id         usuario  \\\n",
       "0  770567971701940224  wikimiscojones   \n",
       "1  770503386789711872    HLF_Metr4spt   \n",
       "2  770502863017635840      AVazquez_C   \n",
       "3  770599972102348800      minniecris   \n",
       "4  770599962216390656      VI_Lelouch   \n",
       "\n",
       "                                               Texto                Fecha  \\\n",
       "0  @LonelySoad mientras que no te pillen la prime...  2016-08-30 10:24:55   \n",
       "1  @ceemeese ya era hora de volver al csgo y deja...  2016-08-30 06:08:17   \n",
       "2  @mireiaescribano justo cuando se terminan las ...  2016-08-30 06:06:12   \n",
       "3  @LuisMartinez22_ pensba q iba a hacer @wxplosi...  2016-08-30 12:32:05   \n",
       "4  @Vic_Phantomhive Si lo encuentro, sin compañer...  2016-08-30 12:32:02   \n",
       "\n",
       "  Idioma Polaridad  \n",
       "0     es         N  \n",
       "1     es         N  \n",
       "2     es         N  \n",
       "3     es         N  \n",
       "4     es         P  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_unseen_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = 'tweets_evaluados.csv'\n",
    "df.to_csv(csv,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crearXML(df, filename=None, mode='w'):\n",
    "    def row_to_xml(row):\n",
    "        xml = ['\t<tweet>']\n",
    "        for i, col_name in enumerate(row.index):\n",
    "            if i == 0:\n",
    "                xml.append('\t\t<tweetid>{0}</tweetid>'.format(row.iloc[i]))\n",
    "            elif i == 1:\n",
    "                xml.append('\t\t<user>{0}</user>'.format(row.iloc[i]))\n",
    "            elif i == 2:\n",
    "                xml.append('\t\t<content>{0}</content>'.format(row.iloc[i]))\n",
    "            elif i == 3:\n",
    "                xml.append('\t\t<date>{0}</date>'.format(row.iloc[i]))\n",
    "            elif i == 4:\n",
    "                xml.append('\t\t<lang>{0}</lang>'.format(row.iloc[i]))\n",
    "            elif i == 5:\n",
    "                xml.append('\t\t<sentiment>')\n",
    "                xml.append('\t\t\t<polarity><value>{0}</value></polarity>'.format(row.iloc[i]))\n",
    "                xml.append('\t\t</sentiment>')\n",
    "        xml.append('\t</tweet>')\n",
    "        return '\\n'.join(xml)\n",
    "    res = '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<tweets>\\n'\n",
    "    res += '\\n'.join(df.apply(row_to_xml, axis=1))\n",
    "    res += '\\n</tweets>\\n'\n",
    "\n",
    "    if filename is None:\n",
    "        return res\n",
    "    with open(filename, mode, encoding='utf-8') as f:\n",
    "        f.write(res)\n",
    "\n",
    "crearXML(df,'TASS2017_T1_test_lleno.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
