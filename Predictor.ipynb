{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictor basado en CNN\n",
    "Basado en https://github.com/satojkovic/cnn-text-classification-tf/tree/use_fasttext y https://github.com/jiegzhan/multi-class-text-classification-cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se importa el texto a predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[':-)', ':-))', '(-:', '((-:', ':)', ':))', '(:', '((:', ':-]', '[-:']\n",
      "[':-(', ':(', ':-c', ':c', ':-<', ':<', ':-[', ':[', ':-||', '>:[']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>usuario</th>\n",
       "      <th>Texto</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Idioma</th>\n",
       "      <th>Polaridad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>142532743211917312</td>\n",
       "      <td>carlos__alsina</td>\n",
       "      <td>¿La posición acertada será la Merkel-Sarko-líd...</td>\n",
       "      <td>2011-12-02T10:17:08</td>\n",
       "      <td>es</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>142559090676203520</td>\n",
       "      <td>Federicoquevedo</td>\n",
       "      <td>Ultimo dia de 'cole' esta semana, nada mejor q...</td>\n",
       "      <td>2011-12-02T12:01:50</td>\n",
       "      <td>es</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>142559890332856321</td>\n",
       "      <td>Joss682008</td>\n",
       "      <td>Otra de puertas abiertas. Una paisana de Bono ...</td>\n",
       "      <td>2011-12-02T12:05:01</td>\n",
       "      <td>es</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142599953318023170</td>\n",
       "      <td>VicenteVallesTV</td>\n",
       "      <td>A las 3 en Antena3, ZP deja a Rajoy la aprobac...</td>\n",
       "      <td>2011-12-02T14:44:12</td>\n",
       "      <td>es</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142642819490783233</td>\n",
       "      <td>AlexdelaIglesia</td>\n",
       "      <td>Que frio ☔⚡</td>\n",
       "      <td>2011-12-02T17:34:33</td>\n",
       "      <td>es</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id          usuario  \\\n",
       "0  142532743211917312   carlos__alsina   \n",
       "1  142559090676203520  Federicoquevedo   \n",
       "2  142559890332856321       Joss682008   \n",
       "3  142599953318023170  VicenteVallesTV   \n",
       "4  142642819490783233  AlexdelaIglesia   \n",
       "\n",
       "                                               Texto                Fecha  \\\n",
       "0  ¿La posición acertada será la Merkel-Sarko-líd...  2011-12-02T10:17:08   \n",
       "1  Ultimo dia de 'cole' esta semana, nada mejor q...  2011-12-02T12:01:50   \n",
       "2  Otra de puertas abiertas. Una paisana de Bono ...  2011-12-02T12:05:01   \n",
       "3  A las 3 en Antena3, ZP deja a Rajoy la aprobac...  2011-12-02T14:44:12   \n",
       "4                                        Que frio ☔⚡  2011-12-02T17:34:33   \n",
       "\n",
       "  Idioma Polaridad  \n",
       "0     es         ?  \n",
       "1     es         ?  \n",
       "2     es         ?  \n",
       "3     es         ?  \n",
       "4     es         ?  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Preprocesador import Preprocesador\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "carpetaModeloEntrenado = 'trained_model_1528958572'\n",
    "csvPrueba = 'general-tweets-test1k.csv'\n",
    "\n",
    "preprocesador = Preprocesador()\n",
    "\n",
    "#Definir el nombre de las columnas del archivo\n",
    "cols = ['id','usuario','Texto','Fecha','Idioma','Polaridad']\n",
    "\n",
    "#Importar el archivo en memoria \n",
    "#Se indica que no tiene encabezados\n",
    "#Se usan los nombres definidos anteriormente los nombres de las columnas\n",
    "df = pd.read_csv(csvPrueba,header=None, names=cols)\n",
    "\n",
    "clean_df = df.copy()\n",
    "\n",
    "#Imprimir las primeras líneas del archivo para validar una carga correcta\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se va a pre-procesar el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre procesando tweets...\n",
      "\n",
      "1000 de 1000 tweets procesados\n",
      "Pre procesamiento completado\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>usuario</th>\n",
       "      <th>Texto</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Idioma</th>\n",
       "      <th>Polaridad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>142532743211917312</td>\n",
       "      <td>carlos__alsina</td>\n",
       "      <td>¿la posición acertada será la merkelsarkolíder...</td>\n",
       "      <td>2011-12-02T10:17:08</td>\n",
       "      <td>es</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>142559090676203520</td>\n",
       "      <td>Federicoquevedo</td>\n",
       "      <td>ultimo dia de cole esta semana nada mejor que ...</td>\n",
       "      <td>2011-12-02T12:01:50</td>\n",
       "      <td>es</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>142559890332856321</td>\n",
       "      <td>Joss682008</td>\n",
       "      <td>otra de puertas abiertas una paisana de bono l...</td>\n",
       "      <td>2011-12-02T12:05:01</td>\n",
       "      <td>es</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142599953318023170</td>\n",
       "      <td>VicenteVallesTV</td>\n",
       "      <td>a las xnumx en antenaxnumx zp deja a rajoy la ...</td>\n",
       "      <td>2011-12-02T14:44:12</td>\n",
       "      <td>es</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142642819490783233</td>\n",
       "      <td>AlexdelaIglesia</td>\n",
       "      <td>que frio ☔⚡</td>\n",
       "      <td>2011-12-02T17:34:33</td>\n",
       "      <td>es</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id          usuario  \\\n",
       "0  142532743211917312   carlos__alsina   \n",
       "1  142559090676203520  Federicoquevedo   \n",
       "2  142559890332856321       Joss682008   \n",
       "3  142599953318023170  VicenteVallesTV   \n",
       "4  142642819490783233  AlexdelaIglesia   \n",
       "\n",
       "                                               Texto                Fecha  \\\n",
       "0  ¿la posición acertada será la merkelsarkolíder...  2011-12-02T10:17:08   \n",
       "1  ultimo dia de cole esta semana nada mejor que ...  2011-12-02T12:01:50   \n",
       "2  otra de puertas abiertas una paisana de bono l...  2011-12-02T12:05:01   \n",
       "3  a las xnumx en antenaxnumx zp deja a rajoy la ...  2011-12-02T14:44:12   \n",
       "4                                        que frio ☔⚡  2011-12-02T17:34:33   \n",
       "\n",
       "  Idioma Polaridad  \n",
       "0     es         ?  \n",
       "1     es         ?  \n",
       "2     es         ?  \n",
       "3     es         ?  \n",
       "4     es         ?  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"Pre procesando tweets...\\n\")\n",
    "clean_tweet_texts = []\n",
    "for i in range(df.Texto.count()):\n",
    "    if( (i+1)%1000 == 0 ):\n",
    "        print(\"%d de %d tweets procesados\" % ( i+1, df.Texto.count() ))\n",
    "    clean_tweet_texts.append(preprocesador.tweetCleaner(str(df['Texto'][i])))\n",
    "print (\"Pre procesamiento completado\")\n",
    "\n",
    "clean_df['Texto'] = clean_tweet_texts\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iter(data, batch_size, num_epochs, shuffle=True):\n",
    "    \"\"\"\n",
    "    Generates a batch iterator for a dataset.\n",
    "    \"\"\"\n",
    "    data = np.array(data)\n",
    "    data_size = len(data)\n",
    "    num_batches_per_epoch = int((len(data)-1)/batch_size) + 1\n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle the data at each epoch\n",
    "        if shuffle:\n",
    "            shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "            shuffled_data = data[shuffle_indices]\n",
    "        else:\n",
    "            shuffled_data = data\n",
    "        for batch_num in range(num_batches_per_epoch):\n",
    "            start_index = batch_num * batch_size\n",
    "            end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "            yield shuffled_data[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_unseen_data():\n",
    "    \"\"\"Step 0: load trained model and parameters\"\"\"\n",
    "    checkpoint_dir = carpetaModeloEntrenado\n",
    "    if not checkpoint_dir.endswith('/'):\n",
    "        checkpoint_dir += '/'\n",
    "    checkpoint_file = tf.train.latest_checkpoint(checkpoint_dir + 'checkpoints')\n",
    "    out_dir = os.path.abspath(os.path.join(os.path.curdir, carpetaModeloEntrenado))\n",
    "    params = json.loads(open(os.path.join(out_dir, 'parametros.json')).read())\n",
    "    logging.critical('Loaded the trained model: {}'.format(checkpoint_file))\n",
    "\n",
    "    \"\"\"Step 1: load data for prediction\"\"\"\n",
    "    test_file = sys.argv[2]\n",
    "    test_examples = json.loads(open(test_file).read())\n",
    "\n",
    "    # labels.json was saved during training, and it has to be loaded during prediction\n",
    "    labels = json.loads(open(os.path.join(out_dir, 'labels.json')).read())\n",
    "    one_hot = np.zeros((len(labels), len(labels)), int)\n",
    "    np.fill_diagonal(one_hot, 1)\n",
    "    label_dict = dict(zip(labels, one_hot))\n",
    "\n",
    "    x_test = [str(example) for example in clean_df.Texto]\n",
    "    logging.info('The number of x_test: {}'.format(len(x_test)))\n",
    "\n",
    "    y_test = None\n",
    "\n",
    "    vocab_path = os.path.join(checkpoint_dir, \"vocab\")\n",
    "    vocab_processor = learn.preprocessing.VocabularyProcessor.restore(vocab_path)\n",
    "    x_test = np.array(list(vocab_processor.transform(x_test)))\n",
    "    my_file = Path(\"fasttext_vocabulario.dat\")\n",
    "    preentrenado = my_file.is_file()\n",
    "    if preentrenado:\n",
    "        print('Load pre-trained word vectors')\n",
    "        embedding = np.load('fasttext_embeddings.npy')\n",
    "\n",
    "    \"\"\"Step 2: compute the predictions\"\"\"\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        session_conf = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)\n",
    "        sess = tf.Session(config=session_conf)\n",
    "\n",
    "        with sess.as_default():\n",
    "            saver = tf.train.import_meta_graph(\"{}.meta\".format(checkpoint_file))\n",
    "            saver.restore(sess, checkpoint_file)\n",
    "\n",
    "            input_x = graph.get_operation_by_name(\"input_x\").outputs[0]\n",
    "            dropout_keep_prob = graph.get_operation_by_name(\"dropout_keep_prob\").outputs[0]\n",
    "            embedding_placeholder = graph.get_operation_by_name('embedding/pre_trained').outputs[0]\n",
    "            predictions = graph.get_operation_by_name(\"output/predictions\").outputs[0]\n",
    "\n",
    "            batches = batch_iter(list(x_test), params['batch_size'], 1, shuffle=False)\n",
    "            all_predictions = []\n",
    "            for x_test_batch in batches:\n",
    "                batch_predictions = sess.run(predictions, {input_x: x_test_batch, embedding_placeholder: embedding, dropout_keep_prob: 1.0})\n",
    "                all_predictions = np.concatenate([all_predictions, batch_predictions])\n",
    "\n",
    "    if y_test is not None:\n",
    "        y_test = np.argmax(y_test, axis=1)\n",
    "        correct_predictions = sum(all_predictions == y_test)\n",
    "\n",
    "        logging.critical('The accuracy is: {}'.format(correct_predictions / float(len(y_test))))\n",
    "        logging.critical('The prediction is complete')\n",
    "\n",
    "    # Save the actual labels back to file\n",
    "    actual_labels = [labels[int(prediction)] for prediction in all_predictions]\n",
    "    \n",
    "    for i in range(df.Polaridad.count()):\n",
    "        df.Polaridad[i] = actual_labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:Loaded the trained model: D:\\respaldo joax\\UCR\\Maestria computacion\\2018-1\\NPL\\Deep learning\\trained_model_1528958572\\checkpoints\\model-19600\n",
      "INFO:root:The number of x_test: 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pre-trained word vectors\n",
      "INFO:tensorflow:Restoring parameters from D:\\respaldo joax\\UCR\\Maestria computacion\\2018-1\\NPL\\Deep learning\\trained_model_1528958572\\checkpoints\\model-19600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from D:\\respaldo joax\\UCR\\Maestria computacion\\2018-1\\NPL\\Deep learning\\trained_model_1528958572\\checkpoints\\model-19600\n",
      "C:\\Users\\joax\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>usuario</th>\n",
       "      <th>Texto</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Idioma</th>\n",
       "      <th>Polaridad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>142532743211917312</td>\n",
       "      <td>carlos__alsina</td>\n",
       "      <td>¿La posición acertada será la Merkel-Sarko-líd...</td>\n",
       "      <td>2011-12-02T10:17:08</td>\n",
       "      <td>es</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>142559090676203520</td>\n",
       "      <td>Federicoquevedo</td>\n",
       "      <td>Ultimo dia de 'cole' esta semana, nada mejor q...</td>\n",
       "      <td>2011-12-02T12:01:50</td>\n",
       "      <td>es</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>142559890332856321</td>\n",
       "      <td>Joss682008</td>\n",
       "      <td>Otra de puertas abiertas. Una paisana de Bono ...</td>\n",
       "      <td>2011-12-02T12:05:01</td>\n",
       "      <td>es</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142599953318023170</td>\n",
       "      <td>VicenteVallesTV</td>\n",
       "      <td>A las 3 en Antena3, ZP deja a Rajoy la aprobac...</td>\n",
       "      <td>2011-12-02T14:44:12</td>\n",
       "      <td>es</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142642819490783233</td>\n",
       "      <td>AlexdelaIglesia</td>\n",
       "      <td>Que frio ☔⚡</td>\n",
       "      <td>2011-12-02T17:34:33</td>\n",
       "      <td>es</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id          usuario  \\\n",
       "0  142532743211917312   carlos__alsina   \n",
       "1  142559090676203520  Federicoquevedo   \n",
       "2  142559890332856321       Joss682008   \n",
       "3  142599953318023170  VicenteVallesTV   \n",
       "4  142642819490783233  AlexdelaIglesia   \n",
       "\n",
       "                                               Texto                Fecha  \\\n",
       "0  ¿La posición acertada será la Merkel-Sarko-líd...  2011-12-02T10:17:08   \n",
       "1  Ultimo dia de 'cole' esta semana, nada mejor q...  2011-12-02T12:01:50   \n",
       "2  Otra de puertas abiertas. Una paisana de Bono ...  2011-12-02T12:05:01   \n",
       "3  A las 3 en Antena3, ZP deja a Rajoy la aprobac...  2011-12-02T14:44:12   \n",
       "4                                        Que frio ☔⚡  2011-12-02T17:34:33   \n",
       "\n",
       "  Idioma Polaridad  \n",
       "0     es         N  \n",
       "1     es         P  \n",
       "2     es         N  \n",
       "3     es         N  \n",
       "4     es      NONE  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_unseen_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = 'tweets_evaluados.csv'\n",
    "df.to_csv(csv,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
